{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shimo23333/CLIP-ColorCulture/blob/main/%E8%B7%A8%E6%96%87%E5%8C%96%E8%89%B2%E5%BD%A9%E8%AA%9E%E6%84%8F%E6%AF%94%E8%BC%83%EF%BC%9ACLIP%E4%B8%AD%E8%AA%9E%E8%A8%80%E5%B0%8D%E8%89%B2%E5%BD%A9%E7%90%86%E8%A7%A3%E7%9A%84%E5%B7%AE%E7%95%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qqH8KD3ZKRlr",
        "outputId": "58a93517-7d8a-4225-d856-8e86d9615241"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langsmith 0.3.42 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\n",
            "openai 1.81.0 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\n",
            "google-genai 1.16.1 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCell 1: 套件安裝完成。\n"
          ]
        }
      ],
      "source": [
        "# 1:安裝必要的 Python 套件\n",
        "\n",
        "!pip install -q git+https://github.com/openai/CLIP.git\n",
        "!pip install -q googletrans==4.0.0rc1\n",
        "!pip install -q scikit-image\n",
        "!pip install -q opencv-python # 圖像分析\n",
        "!pip install -q diffusers transformers accelerate invisible-watermark safetensors\n",
        "!pip install -q ipywidgets\n",
        "\n",
        "print(\"1:安裝完成。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-1PgBc5VSiB",
        "outputId": "9538305b-83da-4d35-f3b8-e56a29c81037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 2: 函式庫匯入完成。\n"
          ]
        }
      ],
      "source": [
        "# 2:匯入專案中會用到的所有 Python 模組\n",
        "\n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from googletrans import Translator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from skimage.color import rgb2lab\n",
        "import cv2\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "import textwrap\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "print(\"2:函式庫匯入完成。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJficdoMgRke",
        "outputId": "05139c59-d65d-45a9-9f51-75f22c136f2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 3: 正在設定 Matplotlib CJK 字體 (強化版)...\n",
            "  指定的 CJK 字體文件路徑不存在: /usr/share/fonts/opentype/noto/NotoSansCJKjp-Regular.otf. 回退到通用列表。\n",
            "Cell 3: Matplotlib CJK 字體設定完畢。\n"
          ]
        }
      ],
      "source": [
        "# 3:設定 Matplotlib 字體\n",
        "\n",
        "print(\"3:正在設定 Matplotlib CJK 字體...\")\n",
        "font_path_cjk = '/usr/share/fonts/opentype/noto/NotoSansCJKjp-Regular.otf'\n",
        "if os.path.exists(font_path_cjk):\n",
        "    try:\n",
        "        fm.fontManager.addfont(font_path_cjk)\n",
        "        prop = fm.FontProperties(fname=font_path_cjk)\n",
        "        font_name = prop.get_name()\n",
        "        plt.rcParams['font.family'] = font_name\n",
        "        plt.rcParams['axes.unicode_minus'] = False\n",
        "        print(f\"  已成功設定 CJK 字體為: {font_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  設定字體 '{font_path_cjk}' 時發生錯誤: {e}. 退到通用列表。\")\n",
        "        plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei', 'sans-serif']\n",
        "        plt.rcParams['axes.unicode_minus'] = False\n",
        "else:\n",
        "    print(f\"  指定的 CJK 字體文件路徑不存在: {font_path_cjk}. 退到通用列表。\")\n",
        "    plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei', 'sans-serif']\n",
        "    plt.rcParams['axes.unicode_minus'] = False\n",
        "print(\"3:Matplotlib CJK 字體設定完畢。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9Ha790FVUs4",
        "outputId": "417d5c45-4bab-4b61-d403-5af38b2e94eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 4: 本次運行的計算設備是: cuda\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: 設定 PyTorch 的運算設備\n",
        "\n",
        "if torch.cuda.is_available(): device_to_use = \"cuda\"\n",
        "else: device_to_use = \"cpu\"\n",
        "print(f\"4:本次運行的計算設備是: {device_to_use}\")\n",
        "if device_to_use == \"cpu\": print(\"警告：未使用GPU！運行大型AI模型會非常慢。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHXyIRQgVVYI",
        "outputId": "ed1f7d1a-a144-4672-d0ff-0314c7e862be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 5: 準備載入 CLIP 模型 (ViT-B/32)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████| 338M/338M [00:01<00:00, 221MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  CLIP 模型 (ViT-B/32) 已成功載入到 cuda！\n"
          ]
        }
      ],
      "source": [
        "# 5:載入 OpenAI CLIP 模型\n",
        "\n",
        "clip_model_name_to_load = \"ViT-B/32\"\n",
        "clip_model_instance, clip_image_preprocess_fn = None, None\n",
        "print(f\"5:準備載入 CLIP 模型 ({clip_model_name_to_load})...\")\n",
        "if device_to_use == \"cuda\":\n",
        "    try:\n",
        "        clip_model_instance, clip_image_preprocess_fn = clip.load(clip_model_name_to_load, device=device_to_use)\n",
        "        clip_model_instance.eval()\n",
        "        print(f\"  CLIP 模型 ({clip_model_name_to_load}) 已成功載入到 {device_to_use}！\")\n",
        "        torch.cuda.empty_cache()\n",
        "    except Exception as e: print(f\"  載入CLIP模型時發生錯誤: {e}\")\n",
        "else: print(f\"  未實際載入CLIP模型，因為當前運算設備是 {device_to_use}。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726,
          "referenced_widgets": [
            "f63e1a20488c43b8addbf004f131da3a",
            "ce15756d22134dfa90554ab89c79b284",
            "c5824577c43c4f77871752b29f0e608c",
            "21873ddf9e4a47af94b0500da6d662a2",
            "c1c4e3d2b88c4fb19e8cfd8ac9afa766",
            "94dffe78094f4ee5803c75df665d6fea",
            "722eebd5f47a49b18328a5020e1f96f9",
            "29e44c1f067047c7be31ce3e15ca87ce",
            "8454f77ea1d646bb86eb894bf2799636",
            "e04010b91659442896c9a16d3d750f7b",
            "8acc4ff1e7be41109077665c1a281367",
            "d8bc26e41fcc45d3bcfc060d8dffcaf1",
            "8947ec56019e451eaefd5b0e21080c1d",
            "944e2bc1319d4dcdbd768667effa32b4",
            "e45ecf8fafab45eb82d04784205a1387",
            "3f3260e98a8845cf83efaaa08a783a0b",
            "fa4fac52e1e047bca6ba5e7d6b388df5",
            "acc8f0e27cd147d48242380b83c1345d",
            "c6e4ffa57bfb4f5b8e2e1c62d536f23e",
            "994a0fd66ddc41b5a493cc1f81aecb3a",
            "77505c96577448ec8eaa90bb8877dd7c",
            "7b3be5038310473496d016d1ba905505",
            "430bcb7b22894e36933b9bfe91c79bc9",
            "8ea299ea5fa543959b6e1317ee1ab083",
            "ecc42ac41cd34678b77191689d6b7ba6",
            "e5c3eb6aacb24475aa2d14e423959660",
            "776d8a92f49d44058592bcb5d27b4b49",
            "2b4c684fa718479c94856874bcaaae66",
            "1fe87f013e1f490a990b7cd3b45e3011",
            "499ad020c2a14c57a3dad225c9fa314a",
            "55c9d43b2c9b4ad3bc04f892cecc9a7c",
            "cc2efe2b96404527bce34c50792319b5",
            "076444d5557b46f29eab9cbd52436f03",
            "a86ad1a725f74408b3d88c1e59df9f81",
            "bb4d7188e978444ea1177cfe00bdef61",
            "1214871220ed41d5bba33b404538b971",
            "27bdddd1b48f40fa8bd6ad8f8a589513",
            "463b3d01ef0c42a6afc31cd6cd36efb6",
            "b4f2ddcf857d451e8e5a97e4a947630d",
            "3043b859cf3b4d91ae36fa81651aa420",
            "fa5feb2e301a41b1a8900f9bf1fca90d",
            "fbcf4930709b4f7a9fa1392e539e7531",
            "72d47e46f35f49f1886a097d7c9edb79",
            "9b556003cefc45a3afe51a53f6415f46",
            "7025bd429e2b49a5a558661981025050",
            "9c3fa3b167854bafb644b8d60d5f8177",
            "8c67f3a2d4ed4472af4b70ee44e0db9d",
            "cd14b04505a14414a81b839d4ff1ea93",
            "6db6c15d095440cdb336aee64d341de8",
            "963840ea98eb4d828ae3542b6b143ed8",
            "92730dabce154c04a6365fc3f13a4d0d",
            "91fd22ea8ee244638c7e3b9dca9ad0b8",
            "6a1d2dd03de44ace95f46210288ca7a6",
            "d6128921a8fe452880275f4f1db539d9",
            "8cb6cf64ae1e4cbf99f491eb37c04856",
            "ef3568465eb9450a83bb77200ed0adbb",
            "6909ff44b16842b2bd6b9cec4499308e",
            "ddadbd2f6a5b401ead2a419d431a1006",
            "ed3a24b4f71846ea8296b0020d70fcd7",
            "513b15afcd0b4e97991d2456ed77bc24",
            "5f753f4ec0ea47309778a53459b285f0",
            "20085d6e490546cda0cfd60370303232",
            "64a4015af1434dd9b40fd90f9379015d",
            "ba8e080c66e54d73b47405e1ab2c424e",
            "2d69e1ac2c864ebeb083d67fbcde2e9a",
            "404659d6daa04d9d98780482cadd6a24",
            "ef4ef010803f4415920b6f8abcedd9e1",
            "6f95b38b950440ef8b0963f2161e7d3f",
            "00259ffeb90044e28dd03f4d1f7b82fb",
            "1de09d8411864ffca179011d1bf4c7fa",
            "9af94bcbac894a0e941328e88c6a5587",
            "4c985618f90f41ac963c2bd6d218ee02",
            "62bf85d6e7104cd2a7637b189658f771",
            "5ed8f90995ed4676a9d96a708b6a747d",
            "b10433e2c8e64f498b101276e33e3124",
            "254ff139c9374ae192d34ad7b27ce610",
            "10425434101148d4bbcc990cb1cf436f",
            "de38a3e261d946719308ceb078aa3c21",
            "f6e098b58d984042b409f48ae99a9cde",
            "dbf1d56dcb6b40c58c87120e64cc0f8e",
            "77d42473b9a34ae4ad86394313b0602c",
            "f39d6a597b304173bf452bae67323675",
            "b6cccea2345747f69eaf2e16b5a025bc",
            "6708c7e09c5f470e89554225245a4f92",
            "16d666a8b93f42ac89fb7a5a8dd548ea",
            "7253b8e2df23427e98b8af46bb961914",
            "a8a64cb7eb4a44c388a67334c11e3479",
            "b55151849a214ab3ac240416ca9711e9",
            "03c08cfd011e4e38b4a057c758410742",
            "3a26186865ad451cb8e8e1b1914566f1",
            "d5f5cf5fdb0e4df89eac043db48a5db1",
            "8ab0a42398874af4aaa22894bcb439f2",
            "1c83175325304798819fbf7dfa5c98ea",
            "a0498eb1a2134475852c46b16d3e8696",
            "87adf156577b43ec9d0932be2556ff38",
            "0c254b5852334bd5856612ee8ac8212c",
            "53b94d2411a04b8aaa8d49514045967b",
            "132b46975bd54cd1801fe1538aa22b27",
            "00756ffe2ded4c689764ee786a288d70",
            "baec1a73776d410896dfc44805ec1a9a",
            "fb45449b45954eccaabdb4119eaa5413",
            "8eb6ec9b4f60424e898680c4950d83f3",
            "d827923a2a7b4ca3a136a230ad454180",
            "7bc2201b1d0c49559dff0a28114addb9",
            "2689e79767bf488a92412110a054220c",
            "3889e078099e4451a1072d3ef2620693",
            "7f8d482cbf8c4be7a42461cf17b84d0d",
            "0b4f51c6f79a4b13a22c65812e69fab0",
            "298006210649457aaa0be4e3b483fa2a",
            "ca5818ddf6314de4bd4072c6658ecac2",
            "b89c3ef9210d4ee1ac6129db3861dbd1",
            "545c9cc43a9142f98f058b752fd5c698",
            "6136d6def4ae459e9c987714318986ab",
            "bd2a22d57d274bc8ada5f4e04c288a6a",
            "bf17d22a4f634a54b692fcf5587c14c2",
            "0ef44839631041538b4bb356a7ff552c",
            "104f8ece362046bda62156858ba7d17b",
            "a08b6f1103a6477a9cdb64805c966770",
            "b7f887a647b44f8aa87b2b8b816f3bd2",
            "80fc770571f94a96be0bbe55140b3552",
            "03903843d01a42c8b5d8509c490c1702",
            "758165fd8d564b2da45667cc3d5eed65",
            "95308032cfe54c30bb302da064542832",
            "5f33df3069d04d37abb0223d2fb43285",
            "380280083b1e4ca7b7902e9ef0f11fef",
            "085d8267d12f4effb6f5d75f06459fa0",
            "862c3bfcf5d24d8fb1828988c1d00781",
            "9160cdb3b80644c29529403034f6f800",
            "14b41547723a4b418b9d5f6c4d83c95a",
            "6913b1afab75452ab0643ba5bd294250",
            "15406835d9bc4684b0a68a41359f2657",
            "32eeac973e38425bbc46e0ffde6da2da",
            "169988941172427d9ae5500c51dfa41b",
            "bb8692928f064c6691bdb15116f85bef",
            "12d5511f7a9d49b58bd2bea13aa7b9fb",
            "5df3a6f876924432b2e9257820c1c923",
            "0f987bd248564d07aa4b5db67b0f7f7e",
            "13f03b0490c24dc697b83ed72c88889b",
            "1a96710f1f544ae1ae4f55f84faa8d66",
            "ebab92fe9c254c6e8f7b8e60f6fafe61",
            "e3d4ed9fd864409eacf659c6b71d8342",
            "fd72f68a267b4916807855e6aa1cdaa1",
            "2c19ad7760af41959070f1925e6c9b5a",
            "48116905910a45a7b6afa67360ecb49f",
            "56402639c7494d88b6fc1744f6cbc4cf",
            "0ec7cf09127c4326ba3c86c2897a2db8",
            "85193a35e85540a4b6275025e1d96cf1",
            "31f2ea879c7a4460a5ebeabc655b0b96",
            "d1801a7c39c74eb882282a8c469331e4",
            "7b7355e6908e4c44a9f153a1e8ee1e2c",
            "66f9e7dd4eb74223bbda291576cb63b2",
            "0deb2a5f4af348babed2b9d8e1131626",
            "feeed23dab0147aa9bcd88ffde4906c7",
            "45203d313b5f43e88882e8f1d4f75b27",
            "6fccd09783bf41b297071b85ae19fe1f",
            "b8ce0268146d49828460de4be402f3f0",
            "9e40f3e5919c4133bed44f64c687981c",
            "9917ca390c11495cac7b829cda0f318e",
            "6c7358347c0644e8b27899a260ebdebe",
            "9756a0cd9ff7484393da2cafdcb25bdb",
            "d8ac7f68661f41e2bb1c3992d716edd8",
            "b8abe5c959f04c41a024ec580c258b2e",
            "f98ce4816cb349518df0eacbb6d3c1ad",
            "0582a4b863524a9eb9f2312cc967df0b",
            "54f32c21fb84465e82190c287a23db5e",
            "de55e4f1359346cdb190f900eee82c41",
            "46b5520cc4ef4a16a5cd8bab53ecc486",
            "10c836b227aa4ddb8c7a93eda229a223",
            "6416d075d4bd454799dde8243109686e",
            "938d998a2cb34a80863588a44b6bdde5",
            "faee375ea9b543fcb24f4739af90e35e",
            "747e633c47984cf4bd77fdf50605d171",
            "b63ad13f754741daa8243ed481b61066",
            "d3a1d3ee83764cbd9ad86bc7219e581f",
            "d7ffcf9e277d4a39a443ac1d2f3a605a",
            "51c2c196cc9349a49c8388721eee51a2",
            "1f05b17f32d34eaf9545bb554fb9752a",
            "8a26aaeaba2f463fa14084b2494ddd34",
            "09c6fb4dbf244ce7b77c5f7185e9c62b",
            "2b1122d04c434f2b90c9909afbfe214f",
            "bb80e8ad413d4b53bb3cc496501aef77",
            "c6f0412807b14da0930d3cfd81903ced",
            "246c6702f2354898b300470283835438",
            "c47411b2e3184245b9ea64eff9ca5706",
            "0ae072dd691a4569961e1aa26bb4a5a1",
            "862745d25ef04f8f8222fa1a3fdd976d",
            "85fa78e13ca84b58b47742fbeb1e6cc4"
          ]
        },
        "id": "wsn9eKeLVXMA",
        "outputId": "19b2ce05-8a4a-47c2-be0b-c8d7886d777d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 6: 準備載入 Stable Diffusion 模型 (runwayml/stable-diffusion-v1-5)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f63e1a20488c43b8addbf004f131da3a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model_index.json:   0%|          | 0.00/541 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8bc26e41fcc45d3bcfc060d8dffcaf1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "430bcb7b22894e36933b9bfe91c79bc9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a86ad1a725f74408b3d88c1e59df9f81",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7025bd429e2b49a5a558661981025050",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/617 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef3568465eb9450a83bb77200ed0adbb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "scheduler_config.json:   0%|          | 0.00/308 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef4ef010803f4415920b6f8abcedd9e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/4.72k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de38a3e261d946719308ceb078aa3c21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03c08cfd011e4e38b4a057c758410742",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "baec1a73776d410896dfc44805ec1a9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b89c3ef9210d4ee1ac6129db3861dbd1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "758165fd8d564b2da45667cc3d5eed65",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "169988941172427d9ae5500c51dfa41b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48116905910a45a7b6afa67360ecb49f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "diffusion_pytorch_model.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fccd09783bf41b297071b85ae19fe1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de55e4f1359346cdb190f900eee82c41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f05b17f32d34eaf9545bb554fb9752a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Stable Diffusion 模型 (runwayml/stable-diffusion-v1-5) 已成功載入到 cuda！\n"
          ]
        }
      ],
      "source": [
        "# 6:載入 Stable Diffusion 圖像生成模型\n",
        "\n",
        "sd_model_id_to_load = \"runwayml/stable-diffusion-v1-5\"\n",
        "image_generation_pipeline = None\n",
        "print(f\"6:準備載入 Stable Diffusion 模型 ({sd_model_id_to_load})...\")\n",
        "if device_to_use == \"cuda\":\n",
        "    try:\n",
        "        image_generation_pipeline = StableDiffusionPipeline.from_pretrained(sd_model_id_to_load, torch_dtype=torch.float16)\n",
        "        image_generation_pipeline = image_generation_pipeline.to(device_to_use)\n",
        "        print(f\"  Stable Diffusion 模型 ({sd_model_id_to_load}) 已成功載入到 {device_to_use}！\")\n",
        "        torch.cuda.empty_cache()\n",
        "    except Exception as e: print(f\"  載入Stable Diffusion模型時發生錯誤: {e}\")\n",
        "else: print(f\"  未實際載入Stable Diffusion模型，因為當前運算設備是 {device_to_use}。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoNRlZFNVZZg",
        "outputId": "e2cf518d-1e4c-45ab-ae9d-ee3b7651fcd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 7: 正在初始化 Google 翻譯工具...\n",
            "  Google 翻譯工具初始化成功！測試翻譯 '你好' -> 'Hello'\n"
          ]
        }
      ],
      "source": [
        "# 7:初始化 Google 翻譯工具\n",
        "\n",
        "google_translator_instance = None\n",
        "print(\"7:正在初始化 Google 翻譯工具...\")\n",
        "try:\n",
        "    google_translator_instance = Translator()\n",
        "    test_text = \"你好\"; translated_test_text = google_translator_instance.translate(test_text, src='zh-cn', dest='en').text\n",
        "    print(f\"  Google 翻譯工具初始化成功！測試翻譯 '{test_text}' -> '{translated_test_text}'\")\n",
        "except Exception as e: print(f\"  Google 翻譯工具初始化失敗: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHnIsdO9VYtI",
        "outputId": "20f5304f-4157-4789-e857-81413cd6c424"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 8: 定義了 12 個詞彙概念用於本次分析。\n"
          ]
        }
      ],
      "source": [
        "# 8:定義專案要分析的詞彙概念及多語言翻譯\n",
        "\n",
        "word_concepts_list = [\n",
        "    {\"concept_name\": \"cool_ambiguous\", \"base_chinese\": \"酷 / 涼爽\", \"translations\": {\"zh\": \"冰涼的飲料，酷炫的風格，冷靜的態度\", \"en\": \"cool refreshing drink, cool stylish look, calm and cool attitude\", \"ja\": \"冷たい飲み物、かっこいいスタイル、冷静な態度\", \"ko\": \"시원한 음료, 멋진 스타일, 침착한 태도\"}},\n",
        "    {\"concept_name\": \"soft_ambiguous\", \"base_chinese\": \"柔軟\", \"translations\": {\"zh\": \"柔軟，溫和的觸感，蓬鬆的雲朵\", \"en\": \"soft, gentle touch, fluffy clouds\", \"ja\": \"柔らかい、優しい手触り、ふわふわの雲\", \"ko\": \"부드럽다, 순한 촉감, 푹신한 구름\"}},\n",
        "    {\"concept_name\": \"bright_ambiguous\", \"base_chinese\": \"明亮\", \"translations\": {\"zh\": \"明亮的光線，充滿希望的未來，聰明睿智的想法\", \"en\": \"bright light, hopeful future, intelligent idea\", \"ja\": \"明るい光、希望に満ちた未来、賢いアイデア\", \"ko\": \"밝은 빛, 희망찬 미래, 똑똑한 생각\"}},\n",
        "    {\"concept_name\": \"dark_ambiguous\", \"base_chinese\": \"黑暗\", \"translations\": {\"zh\": \"漆黑的夜晚，神秘的森林深處，陰沉憂鬱的心情\", \"en\": \"dark night, mysterious deep forest, gloomy mood\", \"ja\": \"漆黒の夜、神秘的な森の奥、陰鬱な気分\", \"ko\": \"칠흑 같은 밤, 신비로운 깊은 숲, 침울한 기분\"}},\n",
        "    {\"concept_name\": \"pure_ambiguous\", \"base_chinese\": \"純潔\", \"translations\": {\"zh\": \"純潔的心靈，單純的想法，純淨無瑕的白色\", \"en\": \"pure heart, simple idea, pristine flawless white\", \"ja\": \"純粋な心、単純な考え、清らかで無垢な白\", \"ko\": \"순수한 마음, 단순한 생각, 깨끗하고 티없는 흰색\"}},\n",
        "    {\"concept_name\": \"warm_ambiguous\", \"base_chinese\": \"溫暖\", \"translations\": {\"zh\": \"溫暖的陽光灑在身上，壁爐裡溫暖的火焰，熱情的款待\", \"en\": \"warm sunshine on the skin, cozy fireplace flames, enthusiastic hospitality\", \"ja\": \"肌に注ぐ暖かい日差し、暖炉の暖かい炎、情熱的なもてなし\", \"ko\": \"피부에 내리쬐는 따뜻한 햇살, 벽난로의 따뜻한 불꽃, 열정적인 환대\"}},\n",
        "    {\"concept_name\": \"happy_clear\", \"base_chinese\": \"快樂\", \"translations\": {\"zh\": \"陽光明媚的日子裡孩子們快樂的笑容，五彩繽紛的派對氣球\", \"en\": \"children's happy smiles on a sunny day, colorful party balloons\", \"ja\": \"晴れた日の子供たちの幸せな笑顔、カラフルなパーティーバルーン\", \"ko\": \"화창한 날 아이들의 행복한 미소, 다채로운 파티 풍선\"}},\n",
        "    {\"concept_name\": \"angry_clear\", \"base_chinese\": \"生氣\", \"translations\": {\"zh\": \"因為不公正而生氣的表情，緊握的拳頭，火山爆發的瞬間\", \"en\": \"angry expression due to injustice, clenched fists, moment of volcanic eruption\", \"ja\": \"不正に対する怒りの表情、握りしめた拳、火山噴火の瞬間\", \"ko\": \"불의로 인한 화난 표정, 꽉 쥔 주먹, 화산 폭발의 순간\"}},\n",
        "    {\"concept_name\": \"sad_clear\", \"base_chinese\": \"傷心\", \"translations\": {\"zh\": \"因為失去而傷心的眼淚，陰雨連綿的窗外，孤獨的流浪貓\", \"en\": \"sad tears shed for a loss, continuous rainy weather outside the window, a lonely stray cat\", \"ja\": \"喪失による悲しい涙、窓の外の長引く雨天、孤独な野良猫\", \"ko\": \"상실감에 흘리는 슬픈 눈물, 창밖의 계속되는 비 오는 날씨, 외로운 길고양이\"}},\n",
        "    {\"concept_name\": \"surprised_clear\", \"base_chinese\": \"驚訝\", \"translations\": {\"zh\": \"收到意想不到的生日驚喜時驚訝的表情，魔術師的奇妙戲法\", \"en\": \"surprised expression upon receiving an unexpected birthday surprise, a magician's wonderful trick\", \"ja\": \"予期せぬ誕生日サプライズに驚いた表情、マジシャンの見事な手品\", \"ko\": \"예상치 못한 생일 서프라이즈를 받았을 때 놀란 표정, 마술사의 멋진 마술\"}},\n",
        "    {\"concept_name\": \"hungry_clear\", \"base_chinese\": \"餓\", \"translations\": {\"zh\": \"肚子餓得咕咕叫，餐桌上豐盛美味的晚餐\", \"en\": \"stomach rumbling with hunger, a hearty and delicious dinner on the table\", \"ja\": \"お腹が空いてグーグー鳴る、食卓の上の豊かで美味しい夕食\", \"ko\": \"배가 고파 꼬르륵 소리가 나다, 식탁 위의 푸짐하고 맛있는 저녁 식사\"}},\n",
        "    {\"concept_name\": \"tired_clear\", \"base_chinese\": \"疲憊\", \"translations\": {\"zh\": \"長時間工作後感到身心疲憊，舒適柔軟的床鋪\", \"en\": \"feeling mentally and physically exhausted after long hours of work, a comfortable and soft bed\", \"ja\": \"長時間の仕事の後で心身ともに疲れ果てた、快適で柔らかいベッド\", \"ko\": \"장시간 작업 후 심신이 지친 상태, 편안하고 부드러운 침대\"}},\n",
        "]\n",
        "# word_concepts_to_process = [word_concepts_list[0], word_concepts_list[2]] # 測試時用少量詞彙\n",
        "word_concepts_to_process = word_concepts_list\n",
        "print(f\"8:定義了 {len(word_concepts_to_process)} 個詞彙概念用於本次分析。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08lwE_KgVcDY",
        "outputId": "e3ab8e21-a157-4dc5-bc21-e5b6f2909576"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "輔助函式 `get_clip_text_embeddings_vector` 定義完成。\n"
          ]
        }
      ],
      "source": [
        "# 9:獲取文本的 CLIP 語義嵌入向量\n",
        "# 這個函式使用 CLIP 模型為輸入的各語言文本計算其語義嵌入向量。\n",
        "\n",
        "def get_clip_text_embeddings_vector(text_prompts_dict, loaded_clip_model, computation_device):\n",
        "    if loaded_clip_model is None:\n",
        "        return {lang_code: np.zeros(512, dtype=np.float32) for lang_code in text_prompts_dict}\n",
        "    text_embeddings_result_dict = {}\n",
        "    with torch.no_grad():\n",
        "        for lang_tag, text_content in text_prompts_dict.items():\n",
        "            try:\n",
        "                tokenized_input_text = clip.tokenize([text_content]).to(computation_device)\n",
        "                text_semantic_features = loaded_clip_model.encode_text(tokenized_input_text)\n",
        "                text_semantic_features /= text_semantic_features.norm(dim=-1, keepdim=True)\n",
        "                text_embeddings_result_dict[lang_tag] = text_semantic_features.cpu().numpy().flatten()\n",
        "            except Exception as e:\n",
        "                print(f\"為 '{lang_tag}':'{text_content[:30]}...' 生成CLIP嵌入時出錯: {e}\")\n",
        "                text_embeddings_result_dict[lang_tag] = np.zeros(512, dtype=np.float32)\n",
        "    return text_embeddings_result_dict\n",
        "print(\"9:定義完成。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-X2T_L4VeXx",
        "outputId": "a6ddbc26-6d4d-4b38-81bf-79acf3175185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 10: 輔助函式 `calculate_and_print_embedding_similarity` 定義完成。\n"
          ]
        }
      ],
      "source": [
        "# 10:計算並打印 CLIP 嵌入向量之間的餘弦相似度\n",
        "\n",
        "def calculate_and_print_embedding_similarity(embeddings_dict, reference_lang='en'):\n",
        "    similarity_scores_result = {}\n",
        "    if reference_lang not in embeddings_dict or np.all(np.isclose(embeddings_dict[reference_lang], 0)):\n",
        "        return {f\"{reference_lang}_vs_{lang}\": None for lang in embeddings_dict if lang != reference_lang}\n",
        "    print(f\"  CLIP文本嵌入向量餘弦相似度 (vs '{reference_lang.upper()}'):\")\n",
        "    ref_embedding = embeddings_dict[reference_lang].reshape(1, -1)\n",
        "    for lang, emb in embeddings_dict.items():\n",
        "        if lang == reference_lang: continue\n",
        "        sim_val_str, sim_num = \"N/A (嵌入無效)\", None\n",
        "        if not np.all(np.isclose(emb, 0)):\n",
        "            sim_num = cosine_similarity(ref_embedding, emb.reshape(1, -1))[0][0]\n",
        "            sim_val_str = f\"{sim_num:.3f}\"\n",
        "        similarity_scores_result[f\"{reference_lang}_vs_{lang}\"] = sim_num\n",
        "        print(f\"    - 與 {lang.upper()}: {sim_val_str}\")\n",
        "    return similarity_scores_result\n",
        "print(\"10:定義完成。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FD9ty7FVfFY",
        "outputId": "3e92415f-5fcf-4140-af66-25905965a634"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 11: 輔助函式 `generate_actual_image_with_sd` 定義完成。\n"
          ]
        }
      ],
      "source": [
        "# 11:使用 Stable Diffusion 生成真實圖像\n",
        "\n",
        "def generate_actual_image_with_sd(prompt_text, sd_pipeline, random_seed=42, inference_steps=30, cfg_scale=7.5, computation_device=\"cuda\"):\n",
        "    if sd_pipeline is None:\n",
        "        placeholder_img = Image.new('RGB', (512,512), color='silver'); draw = ImageDraw.Draw(placeholder_img)\n",
        "        try: font = ImageFont.truetype(\"DejaVuSans.ttf\",18)\n",
        "        except: font = ImageFont.load_default()\n",
        "        draw.text((10,10), f\"模型未載入\\n提示:\\n{prompt_text[:70]}...\", fill=(60,60,60), font=font); return placeholder_img\n",
        "    try:\n",
        "        gen = torch.Generator(device=computation_device).manual_seed(random_seed)\n",
        "        with torch.no_grad(): img = sd_pipeline(prompt_text, num_inference_steps=inference_steps, guidance_scale=cfg_scale, generator=gen).images[0]\n",
        "        return img\n",
        "    except Exception as e:\n",
        "        print(f\"  生成圖像時出錯 ('{prompt_text[:40]}...'): {e}\"); error_img = Image.new('RGB', (512,512), color='lightcoral'); draw=ImageDraw.Draw(error_img)\n",
        "        try: font = ImageFont.truetype(\"DejaVuSans.ttf\",15)\n",
        "        except: font = ImageFont.load_default()\n",
        "        draw.text((10,10), f\"圖像生成錯誤:\\n{prompt_text[:60]}...\\n錯誤:\\n{str(e)[:100]}\", fill=(0,0,0),font=font); return error_img\n",
        "print(\"11:定義完成。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynCrt_PoVgio",
        "outputId": "86731c41-1bae-42cf-f75e-efd10a057357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 12: 輔助函式 `extract_dominant_colors_from_image` 定義完成。\n"
          ]
        }
      ],
      "source": [
        "# 12:從圖像中提取主要顏色 (RGB 和 Lab)\n",
        "\n",
        "def extract_dominant_colors_from_image(pil_img, num_colors=5):\n",
        "    if pil_img is None or pil_img.width < num_colors or pil_img.height < num_colors:\n",
        "        rgb = np.array([[128,128,128]]*num_colors, dtype=int); lab = rgb2lab(rgb/255.0).reshape(-1,3); return rgb, lab\n",
        "    try:\n",
        "        img_rgb = pil_img.convert('RGB'); max_dim = 150\n",
        "        ratio = max_dim/max(img_rgb.width, img_rgb.height); new_size=(max(1,int(img_rgb.width*ratio)),max(1,int(img_rgb.height*ratio)))\n",
        "        img_res = img_rgb.resize(new_size, Image.Resampling.LANCZOS); pixels = np.array(img_res).reshape(-1,3)\n",
        "        if pixels.shape[0] < num_colors:\n",
        "            rgb = np.zeros((num_colors,3),dtype=int); actual_rgb = pixels.astype(int)\n",
        "            rgb[:actual_rgb.shape[0]] = actual_rgb\n",
        "            if actual_rgb.shape[0] < num_colors: rgb[actual_rgb.shape[0]:] = np.array([128,128,128])\n",
        "        else:\n",
        "            kmeans = KMeans(n_clusters=num_colors,random_state=0,n_init='auto',max_iter=200).fit(pixels)\n",
        "            rgb = kmeans.cluster_centers_.astype(int)\n",
        "        lab = rgb2lab(rgb.reshape((num_colors,1,3))/255.0).reshape((num_colors,3))\n",
        "        return rgb, lab\n",
        "    except Exception as e:\n",
        "        print(f\"  提取主色調時出錯: {e}\"); rgb_err = np.array([[100,100,100]]*num_colors,dtype=int); lab_err = rgb2lab(rgb_err/255.0).reshape(-1,3); return rgb_err, lab_err\n",
        "print(\"12:定義完成。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMmrvkN9gqLe",
        "outputId": "f940d1eb-242f-47b6-e024-af7f9a30346e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 12.5: 輔助函式 `analyze_global_image_features` 定義完成。\n"
          ]
        }
      ],
      "source": [
        "# 13:分析圖像的全局特徵 (亮度、對比度、飽和度)\n",
        "\n",
        "def analyze_global_image_features(pil_image):\n",
        "    if pil_image is None: return {\"avg_brightness\": \"N/A\", \"contrast_std\": \"N/A\", \"avg_saturation\": \"N/A\"}\n",
        "    try:\n",
        "        cv_bgr = np.array(pil_image.convert('RGB'))[:,:,::-1].copy()\n",
        "        gray = cv2.cvtColor(cv_bgr, cv2.COLOR_BGR2GRAY)\n",
        "        brightness = round(np.mean(gray), 2)\n",
        "        contrast = round(np.std(gray), 2)\n",
        "        hsv = cv2.cvtColor(cv_bgr, cv2.COLOR_BGR2HSV)\n",
        "        saturation = round(np.mean(hsv[:,:,1]), 2)\n",
        "        return {\"avg_brightness\": brightness, \"contrast_std\": contrast, \"avg_saturation\": saturation}\n",
        "    except Exception as e: print(f\"  分析全局圖像特徵時出錯: {e}\"); return {\"avg_brightness\":\"Err\",\"contrast_std\":\"Err\",\"avg_saturation\":\"Err\"}\n",
        "print(\"13:定義完成。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ofRcO9mVigw",
        "outputId": "e3b7d0d9-c970-4731-a0b3-1dd167b12f89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 13: 輔助函式 `generate_explanation_for_image` 定義完成。\n"
          ]
        }
      ],
      "source": [
        "# 14:為生成的圖像準備中文解釋文本\n",
        "\n",
        "def generate_explanation_for_image(chinese_concept, lang_prompt, pil_img, dom_colors_hex=None, global_feats=None):\n",
        "    expl = f\"\\n--- 解釋模板 for 概念:【{chinese_concept}】| 語言提示: 【{lang_prompt[:70]}...】 ---\\n\"\n",
        "    if dom_colors_hex: expl += f\"圖像主要色票 (HEX): {', '.join(dom_colors_hex[:3])} ...\\n\"\n",
        "    if global_feats:\n",
        "        expl += f\"全局圖像特徵: 亮度={global_feats.get('avg_brightness','N/A')}, \"\n",
        "        expl += f\"對比度={global_feats.get('contrast_std','N/A')}, 飽和度={global_feats.get('avg_saturation','N/A')}\\n\"\n",
        "    expl += f\"\\n原因推測與圖像描述 (請您填充)：\\n\"\n",
        "    expl += f\"   [請結合以上客觀指標和您的觀察，詳細闡述：\\n\"\n",
        "    expl += f\"    a. 圖像視覺風格與氛圍？\\n\"\n",
        "    expl += f\"    b. 主要元素與提示詞的關聯？\\n\"\n",
        "    expl += f\"    c. 色彩運用如何詮釋提示詞？\\n\"\n",
        "    expl += f\"    d. (特定語言)文化背景的可能影響？(例如韓國圖像為何常出現人物?)\\n\"\n",
        "    expl += f\"    e. 與其他語言生成圖像的差異及可能原因？]\\n\"\n",
        "    expl += f\"--------------------------------------------------------------------------\\n\"\n",
        "    return expl\n",
        "print(\"14:定義完成。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "f7GRGCkFVkWw",
        "outputId": "99342c81-bfa8-47f4-d4b2-00199cbccb6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 14: 輔助函式 `plot_full_concept_results_chart` 定義完成。\n"
          ]
        }
      ],
      "source": [
        "# 15:輔助函式 - 繪製單個詞彙概念的綜合結果圖表\n",
        "\n",
        "def plot_full_concept_results_chart(concept_id, base_chinese, prompts_dict, images_dict, colors_dict, similarities_dict, global_features_dict=None):\n",
        "    langs = list(prompts_dict.keys()); num_langs = len(langs)\n",
        "    h_ratio, w_ratio = 2.8, 4.0; total_h, total_w = h_ratio*2, w_ratio*num_langs\n",
        "    fig, axs = plt.subplots(2, num_langs, figsize=(total_w, total_h), gridspec_kw={'height_ratios':[0.78,0.22]})\n",
        "    if num_langs==1: axs=axs.reshape(2,1)\n",
        "\n",
        "    title = f\"概念分析: '{base_chinese}' ({concept_id})\\nCLIP相似度(vs EN): \"\n",
        "    sim_strs = [f\"{k.split('_vs_')[-1].upper()}: {v:.2f}\" if isinstance(v,(float,np.floating)) else f\"{k.split('_vs_')[-1].upper()}: {v}\" for k,v in similarities_dict.items()]\n",
        "    fig.suptitle(title + \", \".join(sim_strs), fontsize=11, y=1.04)\n",
        "\n",
        "    for i, lang in enumerate(langs):\n",
        "        img, colors = images_dict.get(lang), colors_dict.get(lang)\n",
        "        global_feats_this_lang = global_features_dict.get(lang, {}) if global_features_dict else {}\n",
        "\n",
        "        ax_img = axs[0,i]; ax_color = axs[1,i]\n",
        "        if img: ax_img.imshow(img)\n",
        "        else: ax_img.text(0.5,0.5,'圖像未生成',ha='center',va='center',transform=ax_img.transAxes)\n",
        "        img_title = f\"{lang.upper()}: \\\"{prompts_dict[lang][:30]}\\\"...\"\n",
        "        if global_feats_this_lang: # 在圖像標題下方添加簡要的全局特徵\n",
        "            img_title += f\"\\n亮:{global_feats_this_lang.get('avg_brightness','-')} \"\n",
        "            img_title += f\"對比:{global_feats_this_lang.get('contrast_std','-')} \"\n",
        "            img_title += f\"飽:{global_feats_this_lang.get('avg_saturation','-')}\"\n",
        "        ax_img.set_title(img_title, fontsize=7.5)\n",
        "        ax_img.axis('off')\n",
        "\n",
        "        if colors:\n",
        "            rgb_patch, lab_patch = colors; n_patch=len(rgb_patch)\n",
        "            patch_canvas = np.zeros((25,100,3),dtype=np.uint8)\n",
        "            patch_w = 100//n_patch if n_patch>0 else 100\n",
        "            for j,rgb_c in enumerate(rgb_patch): patch_canvas[:,j*patch_w:(j+1)*patch_w] = rgb_c\n",
        "            ax_color.imshow(patch_canvas)\n",
        "            lab_str = \"\\n\".join([f\"L{l:.0f} a{a:.0f} b{b:.0f}\" for l,a,b in lab_patch[:min(3,n_patch)]])\n",
        "            ax_color.set_title(f\"Lab(Top{min(3,n_patch)}):\\n{lab_str}\", fontsize=6)\n",
        "        else: ax_color.text(0.5,0.5,'無顏色',ha='center',va='center',transform=ax_color.transAxes)\n",
        "        ax_color.axis('off')\n",
        "    plt.tight_layout(rect=[0,0,1,0.94]); plt.subplots_adjust(hspace=0.5, wspace=0.3); plt.show()\n",
        "print(\"Cell 14: 輔助函式 `plot_full_concept_results_chart` 定義完成。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4xIWQ2ddo63"
      },
      "outputs": [],
      "source": [
        "# 16: 主程式\n",
        "\n",
        "print(f\"Cell 15: 即將開始執行主流程，處理 {len(word_concepts_to_process)} 個詞彙概念...\")\n",
        "BASE_SEED = 20240101 # 可以更改基礎種子以獲得不同的圖像系列\n",
        "SD_STEPS = 22 # 推斷步數可以適當減少以加速，20-25通常是不錯的平衡\n",
        "SD_CFG = 7.0  # 指導比例\n",
        "NUM_DOM_COLORS = 5\n",
        "SAVE_IMAGES_FLAG = True\n",
        "IMAGES_OUT_DIR = \"project_outputs_final_v4\"\n",
        "\n",
        "if SAVE_IMAGES_FLAG and not os.path.exists(IMAGES_OUT_DIR):\n",
        "    os.makedirs(IMAGES_OUT_DIR); print(f\"  已建立圖像儲存目錄: {IMAGES_OUT_DIR}\")\n",
        "\n",
        "results_collection = []\n",
        "\n",
        "for concept_idx, concept_detail in enumerate(tqdm(word_concepts_to_process, desc=\"總體概念處理\")):\n",
        "    concept_id = concept_detail[\"concept_name\"]; base_zh = concept_detail[\"base_chinese\"]\n",
        "    prompts = concept_detail[\"translations\"]\n",
        "    print(f\"\\n\\n處理概念 #{concept_idx+1}: '{base_zh}' ({concept_id})\")\n",
        "\n",
        "    print(\"  [1. CLIP嵌入分析]\")\n",
        "    embeddings = get_clip_text_embeddings_vector(prompts, clip_model_instance, device_to_use)\n",
        "    similarities = calculate_and_print_embedding_similarity(embeddings, reference_lang='en')\n",
        "\n",
        "    print(\"  [2. 圖像生成、顏色與全局特徵分析]\")\n",
        "    concept_images = {}; concept_colors = {}; concept_global_features = {}\n",
        "    concept_explanations_str = \"\"\n",
        "\n",
        "    for lang_idx, (lang, prompt) in enumerate(tqdm(prompts.items(), desc=f\"  '{concept_id}'語言處理\", leave=False)):\n",
        "        print(f\"    -> {lang.upper()}: '{prompt}'\")\n",
        "        img_seed = BASE_SEED + concept_idx*100 + lang_idx*10\n",
        "        pil_img = generate_actual_image_with_sd(prompt,image_generation_pipeline,img_seed,SD_STEPS,SD_CFG,device_to_use)\n",
        "        concept_images[lang] = pil_img\n",
        "\n",
        "        if SAVE_IMAGES_FLAG and pil_img:\n",
        "            try:\n",
        "                fname = f\"{concept_id}_{lang}_s{img_seed}.png\"; fpath = os.path.join(IMAGES_OUT_DIR,fname)\n",
        "                pil_img.save(fpath)\n",
        "            except Exception as e: print(f\"      儲存圖像'{fname}'失敗: {e}\")\n",
        "\n",
        "        rgb_cs, lab_cs = extract_dominant_colors_from_image(pil_img, NUM_DOM_COLORS)\n",
        "        concept_colors[lang] = (rgb_cs, lab_cs)\n",
        "        global_feats = analyze_global_image_features(pil_img) # 分析全局特徵\n",
        "        concept_global_features[lang] = global_feats # 儲存全局特徵\n",
        "\n",
        "        expl_text = generate_explanation_for_image(base_zh, f\"{lang.upper()}: {prompt}\", pil_img,\n",
        "                                                 [f\"#{c[0]:02x}{c[1]:02x}{c[2]:02x}\" for c in rgb_cs],\n",
        "                                                 global_feats) # 傳遞全局特徵給解釋模板\n",
        "        print(expl_text)\n",
        "        concept_explanations_str += expl_text\n",
        "\n",
        "        if device_to_use==\"cuda\": torch.cuda.empty_cache(); time.sleep(0.05)\n",
        "\n",
        "    print(\"\\n  [3. 繪製結果圖表]\")\n",
        "    plot_full_concept_results_chart(concept_id,base_zh,prompts,concept_images,concept_colors,similarities,concept_global_features)\n",
        "\n",
        "    results_collection.append({\"concept\":concept_id,\"base_chinese\":base_zh, \"prompts\":prompts, \"similarities\":similarities,\n",
        "                               \"global_features\": concept_global_features, # 保存全局特徵\n",
        "                               \"explanation_prompts\":concept_explanations_str}) # 保存解釋模板\n",
        "    print(f\"  概念 '{concept_id}' 分析完畢。\")\n",
        "    if device_to_use==\"cuda\": torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\n\\n所有詞彙概念處理完成！解釋模板已在上方打印。\")\n",
        "# 可選: 保存 results_collection 到 JSON\n",
        "# ... (參考之前版本的JSON保存代碼，記得處理NpEncoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nB2p24lZdrq_",
        "outputId": "340d77ba-f6c7-42d2-eaed-e0d5ef7c392e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 16: 正在嘗試清理模型資源...\n",
            "  模型和資源清理操作已執行。\n"
          ]
        }
      ],
      "source": [
        "# 17: 清理模型和資源以釋放\n",
        "\n",
        "print(\"正在清理模型資源...\")\n",
        "if 'clip_model_instance' in globals(): del clip_model_instance\n",
        "if 'clip_image_preprocess_fn' in globals(): del clip_image_preprocess_fn\n",
        "if 'image_generation_pipeline' in globals(): del image_generation_pipeline\n",
        "if device_to_use==\"cuda\": torch.cuda.empty_cache()\n",
        "print(\"  模型和資源清理操作已執行。\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyP0y+fNBrqEkKkPscBENTJM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}